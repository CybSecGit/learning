# Module 6: Testing, CI/CD, and Production Patterns
## Week 6: Because "It Works on My Machine" Isn't a Deployment Strategy

> "Testing is like going to the gym. Everyone knows they should do it, most people don't, and those who do love to talk about it way too much."

## üéØ Module Objectives

By the end of this module, you will:
- Build comprehensive testing strategies that actually catch bugs
- Create CI/CD pipelines that deploy while you sleep (peacefully)
- Implement monitoring that alerts you before users complain
- Master zero-downtime deployments that don't require prayer
- Automate everything that can possibly be automated

## üìö Part 1: Testing Strategy That Scales

### The Testing Pyramid (But Make It Practical)

```typescript
// jest.config.js - Optimized Jest configuration
module.exports = {
  testEnvironment: 'node',
  roots: ['<rootDir>/src', '<rootDir>/tests'],
  testMatch: [
    '**/__tests__/**/*.+(ts|tsx|js)',
    '**/?(*.)+(spec|test).+(ts|tsx|js)',
  ],
  transform: {
    '^.+\\.(ts|tsx)$': ['ts-jest', {
      tsconfig: {
        jsx: 'react-jsx',
      },
    }],
  },
  moduleNameMapper: {
    '^@/(.*)$': '<rootDir>/src/$1',
    '\\.(css|less|scss|sass)$': 'identity-obj-proxy',
  },
  setupFilesAfterEnv: ['<rootDir>/tests/setup.ts'],
  collectCoverageFrom: [
    'src/**/*.{ts,tsx}',
    '!src/**/*.d.ts',
    '!src/**/*.stories.tsx',
  ],
  coverageThreshold: {
    global: {
      branches: 80,
      functions: 80,
      lines: 80,
      statements: 80,
    },
  },
};

// tests/setup.ts - Global test setup
import '@testing-library/jest-dom';
import { TextEncoder, TextDecoder } from 'util';

// Polyfills for Node.js environment
global.TextEncoder = TextEncoder;
global.TextDecoder = TextDecoder;

// Mock next/router
jest.mock('next/router', () => ({
  useRouter: () => ({
    push: jest.fn(),
    pathname: '/',
    query: {},
    asPath: '/',
  }),
}));

// Mock environment variables
process.env = {
  ...process.env,
  NEXT_PUBLIC_API_URL: 'http://localhost:3000',
};
```

### Unit Testing: The Foundation

```typescript
// src/utils/validation.ts
export const validateEmail = (email: string): boolean => {
  const regex = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
  return regex.test(email);
};

export const validatePassword = (password: string): {
  isValid: boolean;
  errors: string[];
} => {
  const errors: string[] = [];
  
  if (password.length < 8) {
    errors.push('Password must be at least 8 characters');
  }
  if (!/[A-Z]/.test(password)) {
    errors.push('Password must contain an uppercase letter');
  }
  if (!/[a-z]/.test(password)) {
    errors.push('Password must contain a lowercase letter');
  }
  if (!/[0-9]/.test(password)) {
    errors.push('Password must contain a number');
  }
  
  return {
    isValid: errors.length === 0,
    errors,
  };
};

// src/utils/__tests__/validation.test.ts
import { validateEmail, validatePassword } from '../validation';

describe('validateEmail', () => {
  test.each([
    ['valid@email.com', true],
    ['also.valid+tag@email.co.uk', true],
    ['invalid.email', false],
    ['@invalid.com', false],
    ['invalid@', false],
    ['', false],
  ])('validates %s as %s', (email, expected) => {
    expect(validateEmail(email)).toBe(expected);
  });
});

describe('validatePassword', () => {
  test('accepts valid passwords', () => {
    const result = validatePassword('ValidPass123');
    expect(result.isValid).toBe(true);
    expect(result.errors).toHaveLength(0);
  });
  
  test('rejects weak passwords with specific errors', () => {
    const result = validatePassword('weak');
    expect(result.isValid).toBe(false);
    expect(result.errors).toContain('Password must be at least 8 characters');
    expect(result.errors).toContain('Password must contain an uppercase letter');
    expect(result.errors).toContain('Password must contain a number');
  });
});
```

### Integration Testing: Where Components Meet

```typescript
// src/components/__tests__/LoginForm.test.tsx
import { render, screen, waitFor } from '@testing-library/react';
import userEvent from '@testing-library/user-event';
import { LoginForm } from '../LoginForm';
import { signIn } from 'next-auth/react';

// Mock NextAuth
jest.mock('next-auth/react', () => ({
  signIn: jest.fn(),
}));

describe('LoginForm', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });
  
  test('submits form with valid credentials', async () => {
    const user = userEvent.setup();
    (signIn as jest.Mock).mockResolvedValueOnce({ ok: true });
    
    render(<LoginForm />);
    
    await user.type(screen.getByLabelText(/email/i), 'test@example.com');
    await user.type(screen.getByLabelText(/password/i), 'ValidPass123');
    await user.click(screen.getByRole('button', { name: /sign in/i }));
    
    await waitFor(() => {
      expect(signIn).toHaveBeenCalledWith('credentials', {
        email: 'test@example.com',
        password: 'ValidPass123',
        redirect: false,
      });
    });
  });
  
  test('shows validation errors for invalid input', async () => {
    const user = userEvent.setup();
    
    render(<LoginForm />);
    
    await user.type(screen.getByLabelText(/email/i), 'invalid-email');
    await user.click(screen.getByRole('button', { name: /sign in/i }));
    
    expect(await screen.findByText(/invalid email format/i)).toBeInTheDocument();
    expect(signIn).not.toHaveBeenCalled();
  });
});

// src/app/api/posts/__tests__/route.test.ts
import { POST } from '../route';
import { prisma } from '@/lib/prisma';
import { getServerSession } from 'next-auth';

jest.mock('@/lib/prisma', () => ({
  prisma: {
    post: {
      create: jest.fn(),
    },
  },
}));

jest.mock('next-auth', () => ({
  getServerSession: jest.fn(),
}));

describe('POST /api/posts', () => {
  test('creates post for authenticated user', async () => {
    (getServerSession as jest.Mock).mockResolvedValueOnce({
      user: { id: '123', email: 'test@example.com' },
    });
    
    (prisma.post.create as jest.Mock).mockResolvedValueOnce({
      id: '456',
      title: 'Test Post',
      content: 'Test content',
      authorId: '123',
    });
    
    const request = new Request('http://localhost:3000/api/posts', {
      method: 'POST',
      body: JSON.stringify({
        title: 'Test Post',
        content: 'Test content',
      }),
    });
    
    const response = await POST(request);
    const data = await response.json();
    
    expect(response.status).toBe(201);
    expect(data.title).toBe('Test Post');
    expect(prisma.post.create).toHaveBeenCalled();
  });
});
```

### E2E Testing with Playwright

```typescript
// playwright.config.ts
import { defineConfig, devices } from '@playwright/test';

export default defineConfig({
  testDir: './tests/e2e',
  fullyParallel: true,
  forbidOnly: !!process.env.CI,
  retries: process.env.CI ? 2 : 0,
  workers: process.env.CI ? 1 : undefined,
  reporter: [
    ['html'],
    ['junit', { outputFile: 'test-results/junit.xml' }],
  ],
  use: {
    baseURL: 'http://localhost:3000',
    trace: 'on-first-retry',
    screenshot: 'only-on-failure',
  },
  projects: [
    {
      name: 'chromium',
      use: { ...devices['Desktop Chrome'] },
    },
    {
      name: 'Mobile Chrome',
      use: { ...devices['Pixel 5'] },
    },
  ],
  webServer: {
    command: 'pnpm start',
    port: 3000,
    reuseExistingServer: !process.env.CI,
  },
});

// tests/e2e/auth.spec.ts
import { test, expect } from '@playwright/test';

test.describe('Authentication Flow', () => {
  test('user can sign up, sign in, and sign out', async ({ page }) => {
    // Sign up
    await page.goto('/auth/signup');
    await page.fill('[name="email"]', 'newuser@example.com');
    await page.fill('[name="password"]', 'ValidPass123');
    await page.fill('[name="confirmPassword"]', 'ValidPass123');
    await page.click('button[type="submit"]');
    
    await expect(page).toHaveURL('/dashboard');
    await expect(page.locator('text=Welcome')).toBeVisible();
    
    // Sign out
    await page.click('button:has-text("Sign Out")');
    await expect(page).toHaveURL('/');
    
    // Sign in
    await page.goto('/auth/signin');
    await page.fill('[name="email"]', 'newuser@example.com');
    await page.fill('[name="password"]', 'ValidPass123');
    await page.click('button[type="submit"]');
    
    await expect(page).toHaveURL('/dashboard');
  });
  
  test('protected routes redirect to signin', async ({ page }) => {
    await page.goto('/dashboard');
    await expect(page).toHaveURL('/auth/signin');
  });
});
```

## üöÄ Part 2: CI/CD with GitHub Actions

### The Complete CI/CD Pipeline

```yaml
# .github/workflows/ci-cd.yml
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  NODE_VERSION: '20'
  PNPM_VERSION: '8'

jobs:
  # Job 1: Code Quality
  quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'
      
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      
      - name: Run linting
        run: pnpm lint
      
      - name: Run type checking
        run: pnpm typecheck
      
      - name: Check formatting
        run: pnpm format:check

  # Job 2: Tests
  test:
    name: Test Suite
    runs-on: ubuntu-latest
    needs: quality
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'
      
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      
      - name: Setup test database
        run: |
          pnpm prisma migrate deploy
          pnpm prisma db seed
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test
      
      - name: Run unit tests
        run: pnpm test:unit --coverage
      
      - name: Run integration tests
        run: pnpm test:integration
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage/lcov.info

  # Job 3: E2E Tests
  e2e:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: quality
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'
      
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      
      - name: Install Playwright browsers
        run: pnpm exec playwright install --with-deps chromium
      
      - name: Build application
        run: pnpm build
      
      - name: Run E2E tests
        run: pnpm test:e2e
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: playwright-report
          path: playwright-report/

  # Job 4: Build and Deploy
  deploy:
    name: Build and Deploy
    runs-on: ubuntu-latest
    needs: [test, e2e]
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'
      
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      
      - name: Build application
        run: pnpm build
        env:
          NEXT_PUBLIC_API_URL: ${{ secrets.PRODUCTION_API_URL }}
      
      - name: Deploy to Vercel
        run: |
          pnpm vercel deploy --prod --token=${{ secrets.VERCEL_TOKEN }}
      
      - name: Run Lighthouse CI
        run: |
          pnpm lhci autorun
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}
```

### Makefile CI/CD Integration

```makefile
# CI/CD Makefile targets
.PHONY: ci-local
ci-local: ## Run CI pipeline locally
	@echo "$(YELLOW)üîÑ Running CI pipeline locally...$(RESET)"
	@act -j quality
	@act -j test
	@act -j e2e

.PHONY: ci-validate
ci-validate: ## Validate GitHub Actions workflows
	@echo "$(YELLOW)‚úì Validating workflows...$(RESET)"
	@actionlint .github/workflows/*.yml

# Deployment automation
.PHONY: deploy
deploy: ## Smart deployment based on branch
	@current_branch=$$(git rev-parse --abbrev-ref HEAD); \
	if [ "$$current_branch" = "main" ]; then \
		make deploy-production; \
	elif [ "$$current_branch" = "staging" ]; then \
		make deploy-staging; \
	else \
		echo "$(YELLOW)Branch $$current_branch is not configured for deployment$(RESET)"; \
	fi

.PHONY: rollback-production
rollback-production: ## Rollback production deployment
	@echo "$(RED)‚è™ Rolling back production...$(RESET)"
	@vercel rollback --token=$(VERCEL_TOKEN)
	@make notify-rollback

# Release automation
.PHONY: release-preview
release-preview: ## Preview what will be released
	@echo "$(YELLOW)üìã Release preview:$(RESET)"
	@standard-version --dry-run

.PHONY: release-patch
release-patch: check-all ## Release patch version
	@standard-version --release-as patch
	@git push --follow-tags origin main
	@make deploy-production

.PHONY: release-minor
release-minor: check-all ## Release minor version
	@standard-version --release-as minor
	@git push --follow-tags origin main
	@make deploy-production
```

## üîç Part 3: Monitoring and Observability

### Application Performance Monitoring

```typescript
// lib/monitoring.ts
import * as Sentry from '@sentry/nextjs';

// Initialize Sentry
Sentry.init({
  dsn: process.env.NEXT_PUBLIC_SENTRY_DSN,
  environment: process.env.NODE_ENV,
  tracesSampleRate: process.env.NODE_ENV === 'production' ? 0.1 : 1.0,
  integrations: [
    new Sentry.BrowserTracing(),
    new Sentry.Replay({
      maskAllText: true,
      blockAllMedia: true,
    }),
  ],
  beforeSend(event, hint) {
    // Filter out known non-issues
    if (event.exception?.values?.[0]?.value?.includes('ResizeObserver')) {
      return null;
    }
    return event;
  },
});

// Custom error boundary
import { ErrorBoundary } from '@sentry/nextjs';

export function AppErrorBoundary({ children }: { children: React.ReactNode }) {
  return (
    <ErrorBoundary
      fallback={({ error, resetError }) => (
        <div className="error-boundary">
          <h2>Something went wrong</h2>
          <details>
            <summary>Error details</summary>
            <pre>{error.message}</pre>
          </details>
          <button onClick={resetError}>Try again</button>
        </div>
      )}
      showDialog
    >
      {children}
    </ErrorBoundary>
  );
}

// Performance monitoring utilities
export function measurePerformance(metricName: string) {
  return function (
    target: any,
    propertyKey: string,
    descriptor: PropertyDescriptor
  ) {
    const originalMethod = descriptor.value;
    
    descriptor.value = async function (...args: any[]) {
      const start = performance.now();
      const transaction = Sentry.startTransaction({
        name: `${metricName}.${propertyKey}`,
      });
      
      try {
        const result = await originalMethod.apply(this, args);
        const duration = performance.now() - start;
        
        transaction.setMeasurement('duration', duration, 'millisecond');
        transaction.setStatus('ok');
        
        return result;
      } catch (error) {
        transaction.setStatus('internal_error');
        throw error;
      } finally {
        transaction.finish();
      }
    };
    
    return descriptor;
  };
}
```

### Health Checks and Status Page

```typescript
// app/api/health/route.ts
import { prisma } from '@/lib/prisma';
import { redis } from '@/lib/redis';

export async function GET() {
  const checks = {
    status: 'ok',
    timestamp: new Date().toISOString(),
    services: {
      database: 'checking',
      redis: 'checking',
      external_api: 'checking',
    },
  };
  
  // Check database
  try {
    await prisma.$queryRaw`SELECT 1`;
    checks.services.database = 'healthy';
  } catch (error) {
    checks.services.database = 'unhealthy';
    checks.status = 'degraded';
  }
  
  // Check Redis
  try {
    await redis.ping();
    checks.services.redis = 'healthy';
  } catch (error) {
    checks.services.redis = 'unhealthy';
    checks.status = 'degraded';
  }
  
  // Check external API
  try {
    const response = await fetch(process.env.EXTERNAL_API_URL + '/health', {
      signal: AbortSignal.timeout(5000),
    });
    checks.services.external_api = response.ok ? 'healthy' : 'unhealthy';
  } catch (error) {
    checks.services.external_api = 'unhealthy';
    checks.status = 'degraded';
  }
  
  const statusCode = checks.status === 'ok' ? 200 : 503;
  
  return Response.json(checks, { status: statusCode });
}

// Makefile health monitoring
.PHONY: health-check
health-check: ## Check application health
	@echo "$(YELLOW)üè• Checking application health...$(RESET)"
	@response=$$(curl -s -o /dev/null -w "%{http_code}" http://localhost:3000/api/health); \
	if [ "$$response" = "200" ]; then \
		echo "$(GREEN)‚úÖ All systems operational$(RESET)"; \
	else \
		echo "$(RED)‚ùå Health check failed (HTTP $$response)$(RESET)"; \
		curl -s http://localhost:3000/api/health | jq; \
	fi

.PHONY: monitor
monitor: ## Start monitoring dashboard
	@echo "$(BLUE)üìä Starting monitoring dashboard...$(RESET)"
	@tmux new-session -d -s monitor 'watch -n 2 make health-check'
	@tmux split-window -h 'npm run logs:tail'
	@tmux split-window -v 'htop'
	@tmux attach-session -t monitor
```

## üö¢ Part 4: Zero-Downtime Deployment

### Blue-Green Deployment Strategy

```makefile
# Blue-Green deployment
.PHONY: deploy-blue-green
deploy-blue-green: ## Deploy using blue-green strategy
	@echo "$(BLUE)üîµ Starting blue-green deployment...$(RESET)"
	@# Deploy to staging (green)
	@vercel deploy --prebuilt > deployment-url.txt
	@green_url=$$(cat deployment-url.txt)
	@echo "$(GREEN)‚úÖ Green deployment ready at: $$green_url$(RESET)"
	@# Run smoke tests
	@make smoke-test URL=$$green_url
	@# If tests pass, promote to production
	@if [ $$? -eq 0 ]; then \
		echo "$(BLUE)üîÑ Promoting to production...$(RESET)"; \
		vercel alias $$green_url production.example.com; \
		echo "$(GREEN)‚úÖ Deployment complete!$(RESET)"; \
	else \
		echo "$(RED)‚ùå Smoke tests failed, rollback initiated$(RESET)"; \
		exit 1; \
	fi

.PHONY: smoke-test
smoke-test: ## Run smoke tests against URL
	@echo "$(YELLOW)üî• Running smoke tests...$(RESET)"
	@# Check homepage loads
	@curl -f -s -o /dev/null $(URL) || (echo "‚ùå Homepage failed" && exit 1)
	@echo "‚úÖ Homepage loads"
	@# Check API health
	@curl -f -s $(URL)/api/health | jq -e '.status == "ok"' || (echo "‚ùå API unhealthy" && exit 1)
	@echo "‚úÖ API healthy"
	@# Check critical pages
	@for page in /auth/signin /products /about; do \
		curl -f -s -o /dev/null $(URL)$$page || (echo "‚ùå $$page failed" && exit 1); \
		echo "‚úÖ $$page loads"; \
	done
	@echo "$(GREEN)‚úÖ All smoke tests passed!$(RESET)"
```

### Database Migration Strategy

```makefile
# Safe database migrations
.PHONY: migrate-safe
migrate-safe: ## Run migrations with backup
	@echo "$(YELLOW)üóÑÔ∏è  Running safe migration...$(RESET)"
	@# Backup current schema
	@pg_dump $(DATABASE_URL) --schema-only > backup/schema-$$(date +%Y%m%d-%H%M%S).sql
	@# Run migrations
	@pnpx prisma migrate deploy
	@# Verify migrations
	@make health-check

.PHONY: migrate-rollback
migrate-rollback: ## Rollback last migration
	@echo "$(RED)‚è™ Rolling back migration...$(RESET)"
	@latest_backup=$$(ls -t backup/schema-*.sql | head -1)
	@if [ -z "$$latest_backup" ]; then \
		echo "$(RED)No backup found!$(RESET)"; \
		exit 1; \
	fi
	@echo "Restoring from $$latest_backup"
	@psql $(DATABASE_URL) < $$latest_backup
```

## üèóÔ∏è Module Project: Production-Ready Platform

Build a complete production platform with:

```makefile
# Production Platform Makefile
.PHONY: platform-status
platform-status: ## Show platform status dashboard
	@echo "$(BOLD)$(BLUE)Platform Status Dashboard$(RESET)"
	@echo "========================="
	@echo ""
	@echo "$(YELLOW)Services:$(RESET)"
	@make health-check
	@echo ""
	@echo "$(YELLOW)Performance:$(RESET)"
	@curl -s http://localhost:3000/api/metrics | jq '.performance'
	@echo ""
	@echo "$(YELLOW)Recent Deployments:$(RESET)"
	@vercel list --token=$(VERCEL_TOKEN) | head -5
	@echo ""
	@echo "$(YELLOW)Error Rate (Last Hour):$(RESET)"
	@# Query your monitoring service

.PHONY: incident-response
incident-response: ## Start incident response workflow
	@echo "$(RED)üö® INCIDENT RESPONSE ACTIVATED$(RESET)"
	@# Create incident channel
	@incident_id=$$(date +%Y%m%d-%H%M%S)
	@echo "Incident ID: $$incident_id"
	@# Capture current state
	@make platform-status > incidents/$$incident_id-status.log
	@make logs-export > incidents/$$incident_id-logs.log
	@# Notify team
	@make notify-incident ID=$$incident_id
	@echo "$(YELLOW)Next steps:$(RESET)"
	@echo "1. Check incidents/$$incident_id-*.log"
	@echo "2. Run 'make rollback-production' if needed"
	@echo "3. Update incident log"
```

## üß™ Hands-On Exercises

### Exercise 1: Complete Testing Suite
Implement:
- Unit tests with 90%+ coverage
- Integration tests for all API endpoints
- E2E tests for critical user journeys
- Performance tests with benchmarks

### Exercise 2: CI/CD Pipeline
Create a pipeline that:
- Runs different test types in parallel
- Deploys preview environments for PRs
- Automates changelog generation
- Notifies team on failures

### Exercise 3: Monitoring Dashboard
Build monitoring that includes:
- Real-time error tracking
- Performance metrics
- User analytics
- Custom business metrics

## ‚úÖ Module Completion Checklist

Before moving to Module 7, ensure you can:

- [ ] Write comprehensive test suites
- [ ] Create CI/CD pipelines with GitHub Actions
- [ ] Implement monitoring and alerting
- [ ] Perform zero-downtime deployments
- [ ] Handle rollbacks gracefully
- [ ] Automate incident response

## üìö Additional Resources

- [Testing Library Best Practices](https://testing-library.com/docs/guiding-principles)
- [GitHub Actions Documentation](https://docs.github.com/en/actions)
- [Playwright Documentation](https://playwright.dev/)

## üéØ Next Steps

You've mastered production patterns! You can now:
- Deploy with confidence
- Catch bugs before users do
- Monitor and respond to issues quickly

**Ready for the capstone?** Continue to [Module 7: Full-Stack Project](/learning-plans/makefile-nextjs/module-7)

---

*Remember: In development, optimism is a bug. In production, paranoia is a feature. Test everything, trust nothing, and always have a rollback plan.*